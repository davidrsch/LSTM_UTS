<p>Batch size?</p>
<p>As explained in <a href = "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/"> Difference between a batch and an epoch in a neural network </a>, batch size is the amount of sample to pass through the model before updating the internal parameters. There are three types of batch size:</p>
<ol>
<li><strong>Batch Gradient Descent.</strong> Batch Size equal to Size of Training Set.</li>
</br>
<li><strong>Stochastic Gradient Descent.</strong> Batch Size equal to 1.</li>
</br>
<li><strong>Mini-Batch Gradient Descent.</strong> Batch Size bigger than 1 and less than Training Set. (Between the most popular mini-batch gradient descent sizes are: 32, 64 and 128)</li>
</ol>
<p>Epoch?</p>
<p>As explained in <a href = "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/"> Difference between a batch and an epoch in a neural network </a>, the defined amount of epoch is the number of times in which the learning algorithm will be executed in the totality of the training data</p>
<p>How many times a model must be test?</p>
<p>Due to the learning process of an ANN can be understood as a stochastic process, because as explained in <a href = "https://towardsdaatascience.com/how-do-artificial-neural-networks-learn-773e46399fc7"> Learning process of a neural network </a> , the learning algorithm start often with random values, it is necessary to determine an amount of test to do. This will help to obtain the average effectiveness of a model with the same features.</p>
<p><i>Note:</i> Default amount it is 10. The user is able to set the desire amount.</p>
